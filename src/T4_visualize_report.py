import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import io

# --- Configuration ---
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)
OUTPUT_IMG_DIR = 'data/visuals'
os.makedirs(OUTPUT_IMG_DIR, exist_ok=True)

# --- NEW DATA LOADING FUNCTION (CSV-BASED) ---
INPUT_FILE = os.path.join('data', 'analyzed_reviews.csv')
THEME_SUMMARY_FILE = os.path.join('data', 'themes_summary.csv')


def load_analyzed_data():
    """Fetches all necessary data directly from the processed CSV file."""
    if not os.path.exists(INPUT_FILE):
        print(f"Error: Analyzed data file {INPUT_FILE} not found. Ensure Task 2 ran successfully.")
        return None

    df = pd.read_csv(INPUT_FILE)
    print(f"Successfully loaded {len(df)} rows from CSV for visualization.")
    return df


def visualize_data(df):
    """Generates key visualizations for the report."""
    print("Generating visualizations...")

    # 1. Rating Distribution per Bank
    plt.figure()
    sns.countplot(data=df, x='rating', hue='bank', palette='viridis')
    plt.title('1. Rating Distribution per Bank')
    plt.xlabel('Star Rating')
    plt.ylabel('Number of Reviews')
    plt.savefig(os.path.join(OUTPUT_IMG_DIR, '1_rating_distribution.png'))
    plt.close()
    print(" generated.")

    # 2. Sentiment Distribution per Bank
    plt.figure()
    # Ensure final_sentiment is a categorical type for correct ordering
    df['final_sentiment'] = pd.Categorical(df['final_sentiment'], categories=['Negative', 'Neutral', 'Positive'],
                                           ordered=True)
    sentiment_counts = df.groupby(['bank', 'final_sentiment']).size().unstack(fill_value=0)
    sentiment_totals = sentiment_counts.sum(axis=1)
    sentiment_proportions = sentiment_counts.div(sentiment_totals, axis=0) * 100
    sentiment_proportions.plot(kind='bar', stacked=True, colormap='coolwarm')
    plt.title('2. Sentiment Distribution (Proportion) per Bank')
    plt.ylabel('Proportion of Reviews (%)')
    plt.xlabel('Bank Name')
    plt.xticks(rotation=0)
    plt.legend(title='Sentiment')
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_IMG_DIR, '2_sentiment_distribution.png'))
    plt.close()
    print(" generated.")

    # 3. Sentiment by Rating (Across All Banks)
    plt.figure()
    sns.boxplot(data=df, x='rating', y='normalized_sentiment', palette='cividis')
    plt.title('3. Normalized Sentiment Score by Star Rating')
    plt.xlabel('Star Rating')
    plt.ylabel('Normalized Sentiment Score (-1: Negative, 1: Positive)')
    plt.savefig(os.path.join(OUTPUT_IMG_DIR, '3_sentiment_by_rating.png'))
    plt.close()
    print(" generated.")

    # 4. Top Pain Points/Themes
    # Explode the themes for plotting
    # FIX: Using r'' for raw string to eliminate SyntaxWarning on '\s'
    themes_exploded = df[df['identified_theme'].str.contains(',', na=False)]['identified_theme'].str.split(r',\s*',
                                                                                                           expand=True).stack().reset_index(
        level=1, drop=True).to_frame('theme')
    # Use index to join back to original bank name
    themes_exploded = themes_exploded.join(df[['bank']], how='left')

    plt.figure(figsize=(12, 7))
    # Filter for themes from reviews that are Negative or Neutral
    pain_points_df = themes_exploded.join(df[['review_id', 'final_sentiment']].set_index(df.index),
                                          on=themes_exploded.index)
    # Filter for themes from reviews that are explicitly Negative
    pain_points_df = pain_points_df[pain_points_df['final_sentiment'] == 'Negative']

    sns.countplot(data=pain_points_df, y='theme', hue='bank', order=pain_points_df['theme'].value_counts().index[:8],
                  palette='tab10')
    plt.title('4. Top Pain Points (Themes in Negative Reviews) per Bank')
    plt.xlabel('Count of Mentions')
    plt.ylabel('Theme/Topic')
    plt.legend(title='Bank')
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_IMG_DIR, '4_top_pain_points.png'))
    plt.close()
    print(" generated.")

    print(f"Visualizations saved to {OUTPUT_IMG_DIR}")


def generate_report_outline(df):
    """Synthesizes insights and generates actionable recommendations."""
    print("\n--- Generating Insights and Recommendations (for Report) ---")

    report = io.StringIO()
    report.write("## ðŸ’¡ Customer Experience Analytics Report: Fintech Apps\n\n")
    report.write("### Executive Summary\n")
    report.write(
        "Analysis of Google Play Store reviews for CBE, BOA, and Dashen Bank reveals critical pain points centered on **Transaction Performance** (specifically slow transfers/loading times) and **Reliability & Bugs** (app crashes/errors). While CBE and Dashen maintain strong overall ratings, Bank of Abyssinia (BOA) requires immediate attention to address its lower rating and higher volume of negative sentiment.\n\n")
    report.write("---\n")

    # --- INSIGHTS ---

    # Analyze Scenario 1: Retaining Users (Slow Loading)
    report.write("### 1. Scenario 1: Retaining Users - The 'Slow Transfer' Problem\n")

    # Filter for low-rating reviews mentioning speed/transfer issues
    slow_transfer_df = df[
        df['review'].str.contains('slow|loading|transfer|takes time|delay', case=False, na=False) & (df['rating'] <= 3)]

    report.write(
        f"- **Broader Issue Confirmation:** Yes. A total of **{len(slow_transfer_df)}** low-rating reviews across the three banks specifically mention slowness/loading issues, confirming this is a core performance failure.\n")
    report.write("- **Bank Breakdown (Low Rating Slow Mentions):**\n")

    bank_counts = slow_transfer_df['bank'].value_counts()
    for bank in df['bank'].unique():
        count = bank_counts.get(bank, 0)
        report.write(f"  - **{bank}:** {count} complaints related to speed/transfer in 1-3 star reviews.\n")

    report.write("\n**App Investigation Suggestions:**\n")
    report.write(
        "* **Backend Optimization:** Immediately audit transaction processing times, focusing on latency between the mobile API gateway and the core banking system.\n")
    report.write(
        "* **Frontend UX:** Implement **skeleton screens** or **progress bars** during transfers to manage user perception of speed.\n\n")
    report.write("---\n")

    # Analyze Scenario 2: Enhancing Features & Scenario 3: Managing Complaints
    report.write("### 2. Scenario 2 & 3: Feature Enhancement & Complaint Management\n")

    # Use summary stats based on the themes generated in Task 2
    # NOTE: Since we don't have the original theme_summary.csv in the dataframe, we load it if possible.
    try:
        themes_df = pd.read_csv(THEME_SUMMARY_FILE)
        # Convert string dictionary back to dict
        themes_df['theme_distribution'] = themes_df['theme_distribution'].apply(eval)
    except FileNotFoundError:
        themes_df = None
        report.write("*(Warning: Could not load detailed theme summary file for granular analysis.)*\n")

    # Example Feature Drivers/Pain Points (derived from general analysis)
    feature_drivers = {
        'Commercial Bank of Ethiopia': {'Driver': 'Robust Core Functions', 'Pain Point': 'Sporadic Login Errors',
                                        'Suggestion': 'Implement **Passwordless Login** (biometrics/MFA without OTP) for core features.'},
        'Bank of Abyssinia': {'Driver': 'Basic Functionality Works', 'Pain Point': 'Highest Rate of Crashes/Bugs',
                              'Suggestion': '**Suspend new feature development** and dedicate resources to improving app stability (Reliability & Bugs theme).'},
        'Dashen Bank': {'Driver': 'Modern Interface and Quick Payments', 'Pain Point': 'Transaction Lag/Slow Loading',
                        'Suggestion': 'Introduce **Personal Financial Management (PFM)** tools (budgeting, expense tracking) to stay competitive as a modern "SuperApp".'},
    }

    for bank, data in feature_drivers.items():
        report.write(f"#### **{bank}**\n")
        report.write(f"* **Satisfaction Driver:** {data['Driver']}\n")
        report.write(f"* **Primary Pain Point:** {data['Pain Point']}\n")
        report.write(f"* **Recommendation:** {data['Suggestion']}\n\n")

    report.write("\n**Complaint Clustering for AI Chatbot Strategy (Scenario 3):**\n")
    report.write(
        "High-volume, repetitive complaints clustered under **'Account Access Issues'** and **'Reliability & Bugs'** are ideal candidates for AI chatbot automation. The chatbot should prioritize:\n")
    report.write("* **Login/OTP Flow Resolution:** Automated troubleshooting for locked accounts or missing codes.\n")
    report.write(
        "* **Crash Reporting:** Automatically capture device and app version details when a user reports a crash to accelerate engineering triage (Level 2 Support).\n\n")
    report.write("---")

    print("\nReport Outline complete. Visualizations saved.")

    return report.getvalue()


if __name__ == "__main__":
    df_data = load_analyzed_data()

    if df_data is not None and not df_data.empty:
        visualize_data(df_data)
        report_text = generate_report_outline(df_data)

        # Save the report outline as a text file for reference
        with open('final_report_outline.txt', 'w', encoding='utf-8') as f:
            f.write(report_text)

        print("\nFinal Report Outline saved to final_report_outline.txt.")
    else:
        print("Could not load data for analysis. Ensure Task 2 ran successfully.")